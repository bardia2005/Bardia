{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4ab84e",
   "metadata": {},
   "source": [
    "# **Probability 1 Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac2459",
   "metadata": {},
   "source": [
    "$\n",
    "\\textcolor{gray}{Student}: \\textit{Bardia Barghi}\n",
    "$\n",
    "\n",
    "$\n",
    "\\textcolor{gray}{Number}: \\textit{610303118}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2655e",
   "metadata": {},
   "source": [
    "### **Part 1**: Calculating Posterior Probabilities With *Discrete Priors*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1d3fd",
   "metadata": {},
   "source": [
    "We first calculate all the *Likelihoods* for different $\\theta$ values.\n",
    "\n",
    "$\\theta$ values are represented by a set of 10 possible values ranging from 0.1 to 1 in 0.1 steps: $\\theta$ $\\in$ $\\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1\\}$\n",
    "\n",
    "With the Prior belief being: $\\space$ $\\pi_{Ghader}(\\theta)$ = $\\{0.05, 0.05, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.05, 0.05\\}$\n",
    "\n",
    "The *Likelihood* for each value of  $\\theta$  (with values `n = 20` and `k = 12`) has a *Binomial* Distribution as written below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f64dd3",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textcolor{cyan}{Likelihood}(\\theta) = \\displaystyle\\binom{20}{12} \\cdot (\\theta) ^ {12} \\cdot (1 - \\theta) ^ 8\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad4868",
   "metadata": {},
   "source": [
    "By having the *likelihood* of each  $\\theta$, We can also calculate the $\\textit{Unnormalized Posterior Probability}$ of $\\theta$ simply by multiplying the *Likelihood* and the *Prior Probability*: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a3dc98",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textcolor{cyan}{Unnormalized \\; Posterior}(\\theta) = P(X ∣ \\theta) ⋅ P(\\theta) = \\text{Likelihood} \\times \\text{Prior}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd36361",
   "metadata": {},
   "source": [
    "The $\\textit{Noramlized Posterior Probability}$ can be derived from dividing the *Unnormalized Posterior* by the summation of *Unnormalized Posterior* for every $\\theta$ $\\in$ $\\pi_{Ghader}$ $\\:$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86039d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textcolor{cyan}{Normalized \\; Posterior}(\\theta) = \\frac{Unnormalized \\; Posterior (\\theta)}{\\sum_{\\theta^`}P(X ∣ \\theta^`) ⋅ P(\\theta^`)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bfa625",
   "metadata": {},
   "source": [
    "We then create these sets one by one: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c50bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb\n",
    "\n",
    "theta_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "prior_probability = [0.05, 0.05, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.05, 0.05]\n",
    "likelihood = [float(format((comb(20, 12) * (i ** 12) * ((1 - i) ** (20 - 12))), 'f')) for i in theta_values]\n",
    "unnormalized_posterior = [prior_probability[i] * likelihood[j] for i in range(10) for j in range(10) if i == j]\n",
    "normalized_posterior = [i / sum(unnormalized_posterior) for i in unnormalized_posterior]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9df363",
   "metadata": {},
   "source": [
    "And finally, We build our table with the data at hand:\n",
    "\n",
    "![Table Image](https://i.ibb.co/b5WDFB2j/Table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3210e",
   "metadata": {},
   "source": [
    "And here's the code snippet for printing out the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "579dfd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Theta  Prior  Likelihood  Unnormalized Posterior  Normalized Posterior\n",
      "0    0.1   0.05    0.000000                0.000000              0.000000\n",
      "1    0.2   0.05    0.000087                0.000004              0.000056\n",
      "2    0.3   0.10    0.003859                0.000386              0.004974\n",
      "3    0.4   0.10    0.035497                0.003550              0.045754\n",
      "4    0.5   0.20    0.120134                0.024027              0.309697\n",
      "5    0.6   0.20    0.179706                0.035941              0.463270\n",
      "6    0.7   0.10    0.114397                0.011440              0.147454\n",
      "7    0.8   0.10    0.022161                0.002216              0.028565\n",
      "8    0.9   0.05    0.000356                0.000018              0.000229\n",
      "9    1.0   0.05    0.000000                0.000000              0.000000\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import comb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 100000\n",
    "\n",
    "theta_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "prior_probability = [0.05, 0.05, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.05, 0.05]\n",
    "likelihood = [float(format((comb(20, 12) * (i ** 12) * ((1 - i) ** (20 - 12))), 'f')) for i in theta_values]\n",
    "unnormalized_posterior = [prior_probability[i] * likelihood[j] for i in range(10) for j in range(10) if i == j]\n",
    "normalized_posterior = [i / sum(unnormalized_posterior) for i in unnormalized_posterior]\n",
    "\n",
    "data = {\n",
    "    \"Theta\": theta_values,\n",
    "    \"Prior\": prior_probability,\n",
    "    \"Likelihood\": likelihood,\n",
    "    \"Unnormalized Posterior\": unnormalized_posterior,\n",
    "    \"Normalized Posterior\": normalized_posterior\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5bf12",
   "metadata": {},
   "source": [
    "And for the final section of this part, we answer some questions:\n",
    "\n",
    "1. $\\text{What is the most likely value of θ before observing the data? (i.e., the value with the highest prior probability)}$\n",
    "\n",
    "$\\textcolor{orange}{Answer}$: `θ = 0.5` and `θ = 0.6`\n",
    "\n",
    "2. $\\text{What is the most likely value of θ after observing the data? (i.e., the value with the highest posterior probability)}$\n",
    "\n",
    "$\\textcolor{orange}{Answer}$: `θ = 0.6`\n",
    "\n",
    "3. $\\text{What is the posterior probability that θ > 0.5?}$\n",
    "\n",
    "$\\textcolor{orange}{Answer}$: NP(θ = 0.6) + NP(θ = 0.7) + NP(θ = 0.8) + NP(θ = 0.9) + NP(θ = 1) = 0.463270 + 0.147454 + 0.028565 + 0.000229 + 0.000000 = `0.639518`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96303b0",
   "metadata": {},
   "source": [
    "### **Part 2**: Calculating Posterior Probabilities With *Continuous Priors*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c475ee",
   "metadata": {},
   "source": [
    "In this part, $\\theta$ can take on values within the (0, 1) interval.\n",
    "\n",
    "A common approach in Bayesian statistics, especially when no specific prior knowledge is available, is to use a **Uniform Prior** over the interval (0,1):\n",
    "\n",
    "$$\n",
    "\\theta{\\quad \\sim \\quad \\text{Uniform(0, 1)}} \\quad \\to \\quad \\theta \\quad \\sim \\quad  \\text{Beta\\text{(1, 1)}}\n",
    "$$\n",
    "\n",
    "Again, We observe data from `n = 20` individuals, and `s = 12` of them respond that **Monday** is their favourite day to buy breakfast, and we use this data to update our *Prior* and obtain *Posterior*:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656d925",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Posterior}(\\theta) \\quad \\sim \\quad \\text{Likelihood}(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f30c143",
   "metadata": {},
   "source": [
    "Precisely:\n",
    "\n",
    "$$\n",
    "\\text{Posterior}(\\theta) \\quad = \\quad \\frac{Likelihood(\\theta)}{\\displaystyle \\int_0^1 Likelihood(\\theta) \\: \\mathrm{d}\\theta} \\quad = \\quad \\frac{\\displaystyle\\binom{20}{12} \\cdot \\theta ^ {12} \\cdot (1 - \\theta) ^ 8\n",
    "}{\\displaystyle \\int_0^1 \\displaystyle\\binom{20}{12} \\cdot \\theta ^ {12} \\cdot (1 - \\theta) ^ 8 \\: \\mathrm{d}\\theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed9d5a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Beta(a, b)} \\quad = \\quad \\displaystyle{\\int_0^1 x^{a - 1} \\cdot (1 - x)^{b - 1}} \\: \\mathrm{d}x \\quad = \\quad \\frac{\\Gamma(a) \\cdot \\Gamma(b)}{\\Gamma(a + b)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb63824",
   "metadata": {},
   "source": [
    "By simplifying the *Posterior* we get:\n",
    "\n",
    "$$\n",
    "\\text{Posterior}(\\theta) \\quad = \\quad \\frac{\\theta^{12} \\cdot (1 - \\theta)^{8}}{\\frac{\\Gamma(13) \\cdot \\Gamma(9)}{\\Gamma(21)}} \\quad = \\quad \\frac{\\Gamma(21)}{\\Gamma(13) \\cdot \\Gamma(9)} \\cdot \\theta^{12} \\cdot (1 - \\theta)^{8} \n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
